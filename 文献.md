# Deformable Convolutional Networks  
Jifeng Dai∗ Haozhi Qi∗,† Yuwen Xiong∗,† Yi Li∗,† Guodong Zhang  
主要看采样和权重方程的定义  
Convolutional neural networks (CNNs) are inherently limited to model geometric transformations due to the fixed geometric structures in their building modules. In this work, we introduce two new modules to enhance the transformation modeling capability of CNNs, namely, deformable convolution and deformable RoI pooling.可变形卷积和可变形池化。  
It adds 2D offsets to the regular grid sampling locations in the standard convolution. It enables free form deformation of the sampling grid. It is illustrated in Figure 1. The offsets are learned from the preceding feature maps, via additional convolutional layers. Thus, the deformation is conditioned on the input features in a local, dense, and adaptive manner.![image](https://user-images.githubusercontent.com/92596875/202897667-d8b4fc09-765c-4ccb-af7b-aea521effe30.png)  
二维偏移量加入常规采样位置，偏移量通过额外的卷积层从前面的特征图中学习。(c)(d) are special cases of (b), showing that the deformable convolution generalizes various transformations for scale, (anisotropic) aspect ratio and rotation.  
![image](https://user-images.githubusercontent.com/92596875/202898416-5b82b532-b706-4b8d-b2f0-f3f7750d72e8.png)  
![image](https://user-images.githubusercontent.com/92596875/202898430-e8465926-41f6-467e-a354-3dea94e18299.png)  
![image](https://user-images.githubusercontent.com/92596875/202898443-ba5efa7d-034d-41e0-84c1-5000e6b86407.png)  
![image](https://user-images.githubusercontent.com/92596875/202898460-427f6411-b4cb-482f-a20e-e57c2735d7bb.png)
![image](https://user-images.githubusercontent.com/92596875/202898709-19c4e759-b4a1-43ca-b452-ae044ab49e5a.png)  
公式1是常规卷积，R里是距中心的偏移量，（0，1）等。从2中看出给每个位置加了偏移量。q是x中的整数位置，p由于偏移量的存在是小数，公式3是双线性插值得到inputfeature在小数位置的值。  
![image](https://user-images.githubusercontent.com/92596875/202898645-fddac021-679a-489d-8f4f-79c55cf84a34.png)  
 通道数2N对应N个2D偏移。  
#  Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition  
![image](https://user-images.githubusercontent.com/92596875/203024131-94b94921-526c-4baf-9ab1-393d32343a45.png)  
时间上的label和空间上不一致，是在空间的基础上再向后延，具体算法及数值看程序  
uni-label
![image](https://user-images.githubusercontent.com/92596875/203034670-b23d8b59-dc4e-41f4-8cf5-17c5796c7815.png)  
![image](https://user-images.githubusercontent.com/92596875/203034730-1ef1d4cd-986f-41e7-8425-099fd430afec.png)  
i代表关节，j就是每个关节和其他关节的关系，有多少邻接全部加起来，包括自接。公式的前半部分邻接阵归一化  
![image](https://user-images.githubusercontent.com/92596875/203036235-d4a4e767-b851-48fa-ba04-804ae5dded09.png)  
multi--  
![image](https://user-images.githubusercontent.com/92596875/203036799-6a100b1a-db6a-4dc0-9423-2809ca61be19.png)  
前面只需要对角线和非对角线元素就可以区分，现在多分类必须使用多个A矩阵。  
![image](https://user-images.githubusercontent.com/92596875/203037265-a2867015-8b14-4da9-8754-77a007d0fdf6.png)  
![image](https://user-images.githubusercontent.com/92596875/203037347-cd99698b-b248-4004-9d03-984d4314715a.png)  
还有一个可学的边界重要性矩阵M，M和A按元素相乘后替换A，M初始化为全1矩阵。  
# SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS    
这篇有GCN的很多底层公式  
# Contrast-reconstruction Representation Learning for Self-supervised Skeleton-based Action Recognition  
**idea:与其通过不同的管道进行对比学习后交换知识，不如直接用这个视角做data augmentation**  
对比度重建表示学习，它主要由三个部分组成：Sequence Reconstructor、Contrastive Motion Learner、Information Fuser。  
Sequence Reconstructor 通过重构从骨架坐标序列中学习表示。为了增强运动的学习，对比运动学习器分别在从坐标序列和附加速度序列学习的表示之间进行对比学习。最后，在信息融合器中，我们探索了结合序列重构器和对比运动学习器的各种策略，以及建议通过基于知识蒸馏的融合策略同时捕获姿势和运动，该策略将运动学习从对比运动学习器转移到序列重建器。  
1. Intro  
从原始坐标中学习的representation倾向于静态姿势，不捕获动作的动态。所以很多动作很难区分，比如跑步和慢跑。  
**所以建议利用速度进行表示学习**  
![image](https://user-images.githubusercontent.com/92596875/203874529-739f3852-c8eb-45d1-8047-d9624c55edcb.png)
![image](https://user-images.githubusercontent.com/92596875/203874643-cc8d4827-6434-4987-99d8-0a754c1d1efb.png)  
1）对比运动学习器（CML）通过最大化速度和骨架序列的学习表示之间的相似性来提取运动动力学； 2）序列重构器（SER）通过坐标序列重构来学习姿势； 3) Information Fuser 通过知识蒸馏将 CML 和 SER 耦合在一起——CML 的查询编码器扮演教师角色，并通过施加蒸馏损失“教”SER 的学生编码器运动动力学。 因此，学生编码器的学习表示捕获了运动动态和姿势信息，然后用于评估。 CML 中的 TAP 表示时间平均池化，用于跨时间聚合信息。  
CML里两个编码器一个学动作，一个学姿势，有点东西，其实就相当于把crossclr里的motion当作一个data augmentation了。
2. 方法  
 A. Sequence Reconstructor  
 ![image](https://user-images.githubusercontent.com/92596875/203973912-befa2a0d-fcbf-4b4a-bd1a-b5f2a1d3ca65.png)  
 这是一个基于RNN的auto-encoder（GRU），同时训练decoder从第一个和最后一个动作中复原整个序列。  
 B. Contrastive Motion Learner  
 速度就是后一个时刻的位置减前一个时刻的位置。MOCO的架构，GRU作为backbone，只不过一个输入速度一个输入关节。
 然后是TAP和MLP做一个非线性转换。  
 ![image](https://user-images.githubusercontent.com/92596875/203978742-974b4294-e988-49df-a686-8ee8ebb2836c.png)
 ![image](https://user-images.githubusercontent.com/92596875/203978769-a0f9b717-8cf7-4e34-86e7-6c57ca69dba3.png)  
 C. Information Fuser  
 主要是知识蒸馏的架构，开山作：Distilling the Knowledge in a Neural Network  
 可以先训练好一个teacher网络，然后将teacher的网络的输出结果  作为student网络的目标，训练student网络，使得student网络的结果p接近q。知识蒸馏，可以将一个网络的知识转移到另一个网络，两个网络可以是同构或者异构。做法是先训练一个teacher网络，然后使用这个teacher网络的输出和数据的真实标签去训练student网络。知识蒸馏，可以用来将网络从大网络转化成一个小网络，并保留接近于大网络的性能；也可以将多个网络的学到的知识转移到一个网络中，使得单个网络的性能接近emsemble的结果。  
 ![image](https://user-images.githubusercontent.com/92596875/203984119-04279233-3b42-440e-ae55-f1b524c56c2d.png)  
 D. Network Training  
 ![image](https://user-images.githubusercontent.com/92596875/203984790-81b860a0-1a96-4e5d-ac2a-0317be02d5c0.png)  
 分为两步，第二步是个联合loss。
# How and What to Learn: Taxonomizing Self-Supervised Learning for 3D Action Recognition
1. 摘要  
两种相互竞争的方法，生成式和对比式。前者试图从隐空间中恢复输入，后者调整隐空间中表示的距离。
